{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import joblib\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from utils import load_utils\n",
    "\n",
    "sys.path.insert(0, \"../utils/\")\n",
    "from data_loader import load_model_data\n",
    "from model_utils import extract_latent_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def perform_correlation(latent_df: pd.DataFrame, \n",
    "    drug_df: pd.DataFrame, \n",
    "    model_name: str, \n",
    "    num_components: int, \n",
    "    shuffle: bool = False):\n",
    "    \"\"\"\n",
    "    Perform Pearson correlation between latent dimensions and drug dependency scores.\n",
    "    \n",
    "    Parameters:\n",
    "    latent_df (pd.DataFrame): Dataframe containing latent dimensions (e.g., PCA/ICA/NMF).\n",
    "    drug_df (pd.DataFrame): Dataframe containing drug dependency scores with `ModelID`.\n",
    "    model_name (str): Name of the model used to extract the latent dimensions (PCA, ICA, NMF).\n",
    "    num_components (int): Number of latent dimensions/components in the model.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Correlation results between latent dimensions and drug scores.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Starting correlation analysis for model: {model_name} with {num_components} components.\")\n",
    "\n",
    "    correlation_results = []\n",
    "    \n",
    "    # Set index to ModelID if present\n",
    "    if 'ModelID' in latent_df.columns:\n",
    "        latent_df = latent_df.set_index('ModelID')\n",
    "        logging.info(\"Set ModelID as index for latent_df.\")\n",
    "    \n",
    "    # Align both dataframes based on the ModelID\n",
    "    common_model_ids = latent_df.index.intersection(drug_df.index)\n",
    "    logging.info(f\"Found {len(common_model_ids)} common ModelIDs.\")\n",
    "\n",
    "    # Filter both dataframes to keep only common ModelIDs\n",
    "    latent_df_filtered = latent_df.loc[common_model_ids]\n",
    "    prism_df_filtered = drug_df.loc[common_model_ids]\n",
    "\n",
    "    # Check and log the variance of each latent dimension and drug response column\n",
    "    latent_variance = latent_df_filtered.var()\n",
    "    prism_variance = prism_df_filtered.var()\n",
    "    \n",
    "    logging.info(f\"Number of latent dimensions with non-zero variance: {(latent_variance != 0).sum()}.\")\n",
    "    logging.info(f\"Number of drug columns with non-zero variance: {(prism_variance != 0).sum()}.\")\n",
    "\n",
    "    # Filter out constant columns (variance == 0)\n",
    "    latent_df_filtered = latent_df_filtered.loc[:, latent_variance != 0]\n",
    "    prism_df_filtered = prism_df_filtered.loc[:, prism_variance != 0]\n",
    "\n",
    "    # Loop over each latent dimension and calculate correlation with each drug\n",
    "    for latent_col in latent_df_filtered.columns:\n",
    "        logging.info(f\"Processing latent dimension: {latent_col}\")\n",
    "        for drug_col in prism_df_filtered.columns:\n",
    "            latent_values = latent_df_filtered[latent_col]\n",
    "            drug_values = prism_df_filtered[drug_col]\n",
    "            \n",
    "            # Check if either column is constant\n",
    "            if latent_values.nunique() <= 1 or drug_values.nunique() <= 1:\n",
    "                corr = np.nan\n",
    "                logging.warning(f\"Skipping correlation for {latent_col} and {drug_col} due to constant values.\")\n",
    "            else:\n",
    "                # Drop missing values for both columns\n",
    "                valid_data = pd.concat([latent_values, drug_values], axis=1).dropna()\n",
    "                latent_values_valid = valid_data[latent_col]\n",
    "                drug_values_valid = valid_data[drug_col]\n",
    "                \n",
    "                if len(latent_values_valid) > 1 and len(drug_values_valid) > 1:\n",
    "                    # Calculate Pearson correlation\n",
    "                    corr, p_value = pearsonr(latent_values_valid, drug_values_valid)\n",
    "                else:\n",
    "                    corr = np.nan\n",
    "                    p_value = np.nan\n",
    "                    logging.warning(f\"Insufficient valid data for correlation between {latent_col} and {drug_col}.\")\n",
    "        \n",
    "            # Store the results\n",
    "            result_row = {\n",
    "                \"z\": int(latent_col.replace(\"z_\", \"\")),\n",
    "                \"full_model_z\": num_components,\n",
    "                \"model\": str(model_name),\n",
    "                \"drug\": str(drug_col),\n",
    "                \"pearson_correlation\": corr,\n",
    "                \"p_value\": p_value,\n",
    "                \"shuffled\": shuffle\n",
    "            }\n",
    "            correlation_results.append(result_row)\n",
    "    \n",
    "    # Convert results into a dataframe\n",
    "    correlation_results_df = pd.DataFrame(correlation_results)\n",
    "    \n",
    "    logging.info(\"Correlation analysis completed.\")\n",
    "    return correlation_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = pathlib.Path(\"../0.data-download/data\").resolve()\n",
    "dependency_file = pathlib.Path(f\"{data_directory}/CRISPRGeneEffect.parquet\").resolve()\n",
    "gene_dict_file = pathlib.Path(f\"{data_directory}/CRISPR_gene_dictionary.parquet\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PRISM data\n",
    "top_dir = \"../5.drug-dependency\"\n",
    "data_dir = \"data\"\n",
    "\n",
    "prism_df, prism_cell_df, prism_trt_df = load_utils.load_prism(\n",
    "    top_dir=top_dir,\n",
    "    data_dir=data_dir,\n",
    "    secondary_screen=False,\n",
    "    load_cell_info=True,\n",
    "    load_treatment_info=True,\n",
    ")\n",
    "\n",
    "# Reset the index and name it ModelID\n",
    "prism_df.reset_index(inplace=True)\n",
    "prism_df.rename(columns={'index': 'ModelID'}, inplace=True)\n",
    "prism_df.set_index('ModelID', inplace=True)\n",
    "prism_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the prism dataframe to shuffle the values without removing the ModelID column\n",
    "prism_df_shuffled = prism_df.copy()\n",
    "\n",
    "# Iterate over each drug column (except 'ModelID') and shuffle its values\n",
    "for drug_col in prism_df_shuffled.columns:\n",
    "    if drug_col != 'ModelID':\n",
    "        # Shuffle the values of the column without resetting the index\n",
    "        prism_df_shuffled[drug_col] = prism_df_shuffled[drug_col].sample(frac=1, random_state=None).values\n",
    "\n",
    "prism_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "metadata_df_dir = pathlib.Path(\"../0.data-download/data/metadata_df.parquet\")\n",
    "metadata = pd.read_parquet(metadata_df_dir)\n",
    "print(metadata.shape)\n",
    "\n",
    "#Load dependency data\n",
    "dependency_df, gene_dict_df = load_model_data(dependency_file, gene_dict_file)\n",
    "dependency_df.head()\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply the scaler to the numeric columns\n",
    "dependency_df[dependency_df.select_dtypes(include=['float64', 'int']).columns] = scaler.fit_transform(\n",
    "    dependency_df.select_dtypes(include=['float64', 'int'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_subbed_dir = pathlib.Path(\"../0.data-download/data/train_and_test_subbed.parquet\")\n",
    "train_and_test_subbed = pd.read_parquet(train_and_test_subbed_dir)\n",
    "\n",
    "\n",
    "# Convert DataFrame to NumPy and then Tensor\n",
    "train_test_array = train_and_test_subbed.to_numpy()\n",
    "train_test_tensor = torch.tensor(train_test_array, dtype=torch.float32)\n",
    "\n",
    "#Create TensorDataset and DataLoader\n",
    "tensor_dataset = TensorDataset(train_test_tensor)\n",
    "train_and_test_subbed_loader = DataLoader(tensor_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the location of the saved models and output directory for correlation results\n",
    "model_save_dir = pathlib.Path(\"../4.gene_expression_signatures/saved_models\")\n",
    "output_dir = pathlib.Path(\"results\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Latent dimensions and model names to iterate over\n",
    "latent_dims = [2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 14, 16, 18, 20, 25, 30, 35, 40, 45, 50, 60, 70, 80, 90, 100, 150, 200]\n",
    "model_names = [\"pca\", \"ica\", \"nmf\", \"vanillavae\", \"betavae\", \"betatcvae\"]\n",
    "\n",
    "# File to store the combined correlation results\n",
    "final_output_file = output_dir / \"combined_latent_drug_correlations.parquet\"\n",
    "try:\n",
    "    combined_results_df = pd.read_parquet(final_output_file)\n",
    "    print(f\"Loaded existing results from {final_output_file}\")\n",
    "except FileNotFoundError:\n",
    "    # If the file doesn't exist, initialize an empty DataFrame\n",
    "    combined_results_df = pd.DataFrame()\n",
    "    logging.error(\"FileNotFoundError: No existing file found. Initialized an empty DataFrame.\")\n",
    "\n",
    "for num_components in latent_dims:\n",
    "    for model_name in model_names:\n",
    "        # Check if this model and latent dimension have already been processed\n",
    "        if not combined_results_df.empty:\n",
    "            if ((combined_results_df['model'] == model_name) & \n",
    "                (combined_results_df['full_model_z'] == num_components)).any():\n",
    "                print(f\"Skipping {model_name} with {num_components} dimensions as it is already processed.\")\n",
    "                continue  # Skip to the next iteration if this combination is already present\n",
    "        \n",
    "        # Load the saved model\n",
    "        model_filename = model_save_dir / f\"{model_name}_{num_components}_components_model.joblib\"\n",
    "        if model_filename.exists():\n",
    "            print(f\"Loading model from {model_filename}\")\n",
    "            model = joblib.load(model_filename)\n",
    "            \n",
    "            latent_df = extract_latent_dims(model_name, model, dependency_df, train_and_test_subbed_loader, metadata)\n",
    "\n",
    "            latent_df.columns = ['ModelID'] + [f'z_{col}' if isinstance(col, int) else col for col in latent_df.columns[1:]]\n",
    "            # Perform Pearson correlation between latent dimensions and drug data\n",
    "            correlation_results_df = perform_correlation(latent_df, prism_df, model_name, num_components)\n",
    "            # Perform Pearson correlation for shuffled data (negative control)\n",
    "            negative_control_results_df = perform_correlation(latent_df, prism_df_shuffled, model_name, num_components, shuffle=True)\n",
    "            # Concatenate results to the combined dataframe\n",
    "            combined_results_df = pd.concat([combined_results_df, correlation_results_df, negative_control_results_df], ignore_index=True)\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Model file {model_filename} not found. Script will terminate.\")\n",
    "\n",
    "\n",
    "# Save the combined results to a parquet file\n",
    "combined_results_df.to_parquet(final_output_file)\n",
    "print(f\"Saved combined results to {final_output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'drug_column_name' is the column in prism_trt_df that matches the 'drug' column in correlation_df\n",
    "prism_trt_df_filtered = prism_trt_df[['column_name', 'name', 'moa', 'target', 'indication', 'phase']]\n",
    "\n",
    "# Merge correlation_df with prism_trt_df based on the 'drug' column in correlation_df and the matching column in prism_trt_df\n",
    "correlation_df_merged = pd.merge(combined_results_df, prism_trt_df_filtered, how='left', left_on='drug', right_on='column_name')\n",
    "\n",
    "# Drop the redundant drug_column_name column after the merge if needed\n",
    "correlation_df_merged = correlation_df_merged.drop(columns=['column_name'])\n",
    "\n",
    "significant_corr_df = correlation_df_merged[\n",
    "    (correlation_df_merged['pearson_correlation'].abs() > 0.1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results_df.sort_values(by='pearson_correlation', key=abs, ascending = False).head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gene_dependency_representations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
