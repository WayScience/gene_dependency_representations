{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hiplot\n",
    "from optuna.visualization import plot_param_importances\n",
    "import optuna\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from betavae import (\n",
    "    BetaVAE,\n",
    "    train_vae,\n",
    "    evaluate_vae\n",
    ")\n",
    "from optimize_utils import(\n",
    "    get_optimize_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load command line arguments\n",
    "args=get_optimize_args()\n",
    "\n",
    "#Load data\n",
    "\n",
    "output_dir = pathlib.Path(\"data\")\n",
    "\n",
    "sys.path.insert(0, \"../0.data-download/scripts/\")\n",
    "from data_loader import load_train_test_data\n",
    "data_directory = pathlib.Path(\"../0.data-download/data\")\n",
    "dfs = load_train_test_data(data_directory, train_or_test = \"all\", load_gene_stats = True)\n",
    "\n",
    "train_feat = dfs[0]\n",
    "test_feat = dfs[1]\n",
    "load_gene_stats = dfs[2]\n",
    "\n",
    "# Prepare data for training\n",
    "train_features_df = train_feat.drop(columns=[\"ModelID\", \"age_and_sex\"])\n",
    "test_features_df = test_feat.drop(columns=[\"ModelID\", \"age_and_sex\"])\n",
    "\n",
    "# subsetting the genes\n",
    "\n",
    "# create dataframe containing the genes that passed an initial QC (see Pan et al. 2022) and their corresponding gene label and extract the gene labels\n",
    "gene_dict_df = pd.read_csv(\"../0.data-download/data/CRISPR_gene_dictionary.tsv\", delimiter='\\t')\n",
    "gene_list_passed_qc = gene_dict_df.query(\"qc_pass\").dependency_column.tolist()\n",
    "\n",
    "# create new training and testing dataframes that contain only the corresponding genes\n",
    "train_df = train_feat.filter(gene_list_passed_qc, axis=1)\n",
    "test_df = test_feat.filter(gene_list_passed_qc, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data\n",
    "train_data = train_df.values.astype(np.float32)\n",
    "test_data = test_df.values.astype(np.float32)\n",
    "\n",
    "# Normalize based on data distribution\n",
    "train_data = (train_data - np.min(train_data, axis=0)) / (np.max(train_data, axis=0) - np.min(train_data, axis=0))\n",
    "test_data = (test_data - np.min(test_data, axis=0)) / (np.max(test_data, axis=0) - np.min(test_data, axis=0))\n",
    "\n",
    "# Convert dataframes to tensors\n",
    "train_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "test_tensor = torch.tensor(test_data, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function: optimized by study\n",
    "    \"\"\"\n",
    "    # Define hyperparameters\n",
    "    latent_dim = trial.suggest_int('latent_dim', args.min_latent_dim, args.max_latent_dim)\n",
    "    beta = trial.suggest_float('beta', args.min_beta, args.max_beta)\n",
    "    learning_rate = trial.suggest_categorical('learning_rate', [5e-3, 1e-3, 1e-4, 1e-5, 1e-6])\n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 48, 80, 112])\n",
    "    epochs = trial.suggest_categorical('epochs', [5, 105, 205, 305, 405, 505, 605, 705, 805, 905])\n",
    "\n",
    "    # Create DataLoader\n",
    "    train_loader = DataLoader(TensorDataset(train_tensor), batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(TensorDataset(test_tensor), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    model = BetaVAE(input_dim=train_df.shape[1], latent_dim=latent_dim, beta=beta)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    \n",
    "    loss = train_vae(model, train_loader, optimizer, epochs=epochs)\n",
    "    \n",
    "    # Evaluate VAE\n",
    "    val_loss = evaluate_vae(model, test_loader)\n",
    "    \n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=500)\n",
    "# Save best hyperparameters\n",
    "best_trial = study.best_trial\n",
    "print(best_trial)\n",
    "print(f'Best trial: {best_trial.values}')\n",
    "print(f'Best hyperparameters: {best_trial.params}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
